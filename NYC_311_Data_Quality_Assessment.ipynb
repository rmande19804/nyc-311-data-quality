# NYC 311 Data Quality Assessment - Jupyter Notebook Template

import pandas as pd

# Load dataset - update path if local
df = pd.read_csv('https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$limit=10000')

# Basic info
print("Dataset shape:", df.shape)
print("\nColumns:\n", df.columns)

# Check missing values %
missing_pct = df.isnull().mean() * 100
print("\nMissing Values Percentage:\n", missing_pct[missing_pct > 0])

# Check duplicates
duplicates = df.duplicated().sum()
print(f"\nNumber of duplicate rows: {duplicates}")

# Unique values for key columns
key_cols = ['complaint_type', 'agency', 'borough']
for col in key_cols:
    unique_vals = df[col].nunique()
    print(f"\nUnique values in {col}: {unique_vals}")

# Sample value counts to find inconsistencies
print("\nSample complaint_type counts:")
print(df['complaint_type'].value_counts().head(10))

# Date consistency check: Created Date and Closed Date
df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')
df['closed_date'] = pd.to_datetime(df['closed_date'], errors='coerce')
date_issues = (df['closed_date'] < df['created_date']).sum()
print(f"\nRows where Closed Date is before Created Date: {date_issues}")

# Save a summary report as CSV for further use if desired
summary = pd.DataFrame({
    'missing_pct': missing_pct,
    'unique_values': df.nunique()
}).sort_values(by='missing_pct', ascending=False)

summary.to_csv('data_quality_summary.csv')

print("\nData quality summary saved as 'data_quality_summary.csv'")
